{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b99a44a1-a8ef-4fa1-bd64-f54f9e893183",
   "metadata": {},
   "source": [
    "# Data aquisition: Speeches BoE 2022 - 2025\n",
    "In order to get the most recent speeches for our analysis, we perform web scraping techniques on the www.bankofengland.co.uk website. This will allow us to obtain the speech date, title, author, and links to each speech's content.\n",
    "\n",
    "In a separate step, we will create a dataframe with this information and then reach out to every link to obtain the actual text of each speech.\n",
    "\n",
    "We will later merge our initial speeches dataset with the one resulting from this procedure. This will ensure the analysis is based on the most comprehensive and updated information available, in line with the project's objectives outlined in the employer brief​Bank of England Project…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "889e7ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd               # for data handling\n",
    "import requests                   # for web scraping\n",
    "from bs4 import BeautifulSoup\n",
    "import re                         # for regular expressions\n",
    "from datetime import datetime\n",
    "from time import sleep            # for introducing pauses \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d19803",
   "metadata": {},
   "source": [
    "### Retrieve speeches metadata from BoE website (scraping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930bedc9-fb93-44c7-8397-eaf3465fc6f1",
   "metadata": {},
   "source": [
    "The scraping focused on the BoE speeches section (https://www.bankofengland.co.uk/news/speeches).\n",
    "The cookie contains a session verification token required for authenticated access. This setup ensures that subsequent requests to the API are correctly authorised, enabling the scraper to retrieve structured data directly rather than parsing HTML pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ce5a209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint and headers\n",
    "url = \"https://www.bankofengland.co.uk/_api/News/RefreshPagedNewsList\"\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"*/*\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.6\",\n",
    "    \"Content-Type\": \"application/x-www-form-urlencoded; charset=UTF-8\",\n",
    "    \"Origin\": \"https://www.bankofengland.co.uk\",\n",
    "    \"Referer\": \"https://www.bankofengland.co.uk/news/speeches\",\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/135.0.0.0 Safari/537.36\",\n",
    "    \"X-Requested-With\": \"XMLHttpRequest\"\n",
    "}\n",
    "\n",
    "# Cookie with session token (replace if expired)\n",
    "cookies = {\n",
    "    \"shell#lang\": \"en\",\n",
    "    \"__RequestVerificationToken\": \"F0TRyiMm0Nwv7WY9BlRedjFyTyzk5BExaj_WC8N-TXLOB75rrftgDCk55SpI9VN0uoMCkj0FqJk3ZD36jWZnPiilGoE1\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2175c6fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'payload' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mpost(url, headers\u001b[38;5;241m=\u001b[39mheaders, cookies\u001b[38;5;241m=\u001b[39mcookies, data\u001b[38;5;241m=\u001b[39mpayload)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to retrieve the page. Status code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'payload' is not defined"
     ]
    }
   ],
   "source": [
    "response = requests.post(url, headers=headers, cookies=cookies, data=payload)\n",
    "if response.status_code != 200:\n",
    "    print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "else:\n",
    "    print(f\"All Good. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cadf2b1",
   "metadata": {},
   "source": [
    "#### Inspect the HTML structure with prettifiy() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4764d05b-8d4c-4999-94ee-0bff2b68f4f6",
   "metadata": {},
   "source": [
    "Using prettify() allow us to see the entire structure of the HTML, so that we can focus on specific items to look into in search of the data we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b353cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# Let's see how this looks\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6269d7",
   "metadata": {},
   "source": [
    "- Each individual speech item was contains within a \"div\" element with a specific class, which groups the title, link, date, and sometimes the speaker's name together.\n",
    "- Speech title and the hyperlink to the full speech page were found inside <a> tags\n",
    "- Publication dates are in a separate \"div\" or \"time\" element\n",
    "- Speakers/authors are inconsistently available: Not all speeches include a named speaker in the listing; some require fetching from the detailed speech page, while others did not list the speaker at all.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c41353c-560b-445f-bf14-0f70fa49f519",
   "metadata": {},
   "source": [
    "Let's print the HTTP response status code to verify if the request was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c55239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.status_code)\n",
    "print(response.text[:500])  # Only first 500 characters to keep it short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a0470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "afcc39d2",
   "metadata": {},
   "source": [
    "### Scraping the metadata for every speech item\n",
    "- In this section, we will create a dataframe with the title, date, and link for every speech listed usin BeautifulSoup.\n",
    "- The approach uses a loop structure to iteratively fetch and parse each page, stopping when no further speeches were found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f1a8bf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 168 speeches to 'boe_speeches_metadata.csv'\n"
     ]
    }
   ],
   "source": [
    "# Set target date range\n",
    "start_date = datetime.strptime(\"2022-10-21\", \"%Y-%m-%d\")\n",
    "today = datetime.today()\n",
    "\n",
    "\n",
    "\n",
    "# Cookie with session token (replace if expired)\n",
    "cookies = {\n",
    "    \"shell#lang\": \"en\",\n",
    "    \"__RequestVerificationToken\": \"F0TRyiMm0Nwv7WY9BlRedjFyTyzk5BExaj_WC8N-TXLOB75rrftgDCk55SpI9VN0uoMCkj0FqJk3ZD36jWZnPiilGoE1\"\n",
    "}\n",
    "\n",
    "# List to store results\n",
    "records = []\n",
    "\n",
    "# Loop through pages\n",
    "for page in range(1, 160):  # Limit to 160 pages to avoid infinite loop\n",
    "    payload = {\n",
    "        \"SearchTerm\": \"\",\n",
    "        \"Id\": \"{CE377CC8-BFBC-418B-B4D9-DBC1C64774A8}\",\n",
    "        \"PageSize\": \"30\",\n",
    "        \"NewsTypesAvailable[]\": \"f949c64a4c88448b9e269d10080b0987\",\n",
    "        \"Page\": str(page),\n",
    "        \"Direction\": \"1\",\n",
    "        \"Grid\": \"false\",\n",
    "        \"InfiniteScrolling\": \"false\"\n",
    "    }\n",
    "\n",
    "    response = requests.post(url, headers=headers, cookies=cookies, data=payload)\n",
    "\n",
    "    if response.status_code != 200:\n",
    "        break\n",
    "\n",
    "    data = response.json()\n",
    "    html = data.get(\"Results\", \"\")\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    items_found = 0\n",
    "\n",
    "    for div in soup.select(\"div.release-content\"):\n",
    "        date_text = div.select_one(\"time.release-date\").text.strip()\n",
    "        try:\n",
    "            date = datetime.strptime(date_text, \"%d %B %Y\")\n",
    "        except ValueError:\n",
    "            continue\n",
    "        if date < start_date:\n",
    "            break\n",
    "        if date > today:\n",
    "            continue\n",
    "\n",
    "        title = div.select_one(\"h3.list\").text.strip()\n",
    "        link = \"https://www.bankofengland.co.uk\" + div.find_parent(\"a\")[\"href\"]\n",
    "        records.append({\"date\": date.strftime(\"%Y-%m-%d\"), \"title\": title, \"link\": link})\n",
    "        items_found += 1\n",
    "\n",
    "    if items_found == 0 or date < start_date:\n",
    "        break                                           # stop when there are no more items\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(records)\n",
    "\n",
    "# Save results to a CSV file\n",
    "#df.to_csv(\"boe_speeches_metadata.csv\", index=False)\n",
    "print(\"Saved\", len(df), \"speeches to 'boe_speeches_metadata.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f54ec2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'C:\\Users\\germa\\OneDrive\\LSE DATA ANALYTICS CAREER ACCELERATOR\\EMPLOYER PROJECT BoE\\speech assigning for test\\speeches.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d3cd02",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a98f1a",
   "metadata": {},
   "source": [
    "### Expanding the data with actual text from each link\n",
    "\n",
    "For each speech URL:\n",
    "- The full speech text was extracted.\n",
    "- A time delay was inserted between requests to respect ethical scraping standards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee218dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "user_agents = [\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)...\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)...\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64)...\",\n",
    "]\n",
    "\n",
    "\n",
    "# Function to extract the full text of a speech from a given BoE speech page\n",
    "def extract_speech_text(url):\n",
    "    headers = {\"User-Agent\": random.choice(user_agents)}\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=10)\n",
    "        if response.status_code != 200:\n",
    "            return f\"HTTP {response.status_code}\"\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        main_section = soup.select_one(\"div#output > section.page-section\")\n",
    "        if not main_section:\n",
    "            return \"Speech section not found\"\n",
    "\n",
    "        paragraphs = main_section.find_all(['p', 'h2', 'h3', 'h4', 'ul', 'ol'])\n",
    "        return \"\\n\\n\".join(p.get_text(separator=\" \", strip=True) for p in paragraphs)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Apply to all rows with a small delay\n",
    "df['speech_text'] = df['link'].apply(lambda url: extract_speech_text(url))\n",
    "\n",
    "sleep(random.uniform(2.5, 20))  # Wait between 2.5 to 20 seconds  # optional: delay between requests if scraping more than a few\n",
    "\n",
    "# Save to new CSV\n",
    "#df.to_csv(\"boe_speeches_speech_text.csv\", index=False)\n",
    "#print(\"Saved\", len(df), \"speeches to boe_speeches_speech_text.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd779fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab80080",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfebc8a",
   "metadata": {},
   "source": [
    "### Extracting speaker name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11c04b9",
   "metadata": {},
   "source": [
    "In the 'title' column, the name of the speaker appears after 'speech by ' string in most of the cases. We can use this to isolate the author and create a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68584818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"boe_speeches_speech_text.csv\")\n",
    "\n",
    "# Combined function to extract speaker's name from title\n",
    "def extract_author_from_title(title):\n",
    "    # Try both types of separators\n",
    "    for separator in [\" − \", \" - \", \" – \"]:\n",
    "        if separator in title:\n",
    "            event_part = title.split(separator)[-1]\n",
    "            match = re.search(r\"\\bby ([\\w\\s\\.\\-']+)\", event_part, re.IGNORECASE)\n",
    "            if match:\n",
    "                return match.group(1).strip()\n",
    "    return None\n",
    "\n",
    "# Apply to rows where 'author' is missing or new extraction is preferred\n",
    "df['author'] = df['title'].apply(extract_author_from_title)\n",
    "\n",
    "\n",
    "# Preview results\n",
    "df[['title', 'author']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08f2763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count nulls in 'author' column\n",
    "null_author_count = df['author'].isnull().sum()\n",
    "print(null_author_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3805bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf70c42",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fce0c3d",
   "metadata": {},
   "source": [
    "### Applying data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd04716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply correct data types\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')  # Parse dates\n",
    "df['title'] = df['title'].astype(str)\n",
    "df['link'] = df['link'].astype(str)\n",
    "df['speech_text'] = df['speech_text'].astype(str)\n",
    "df['author'] = df['author'].astype('string')  # Nullable string type in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8d3352",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2b7c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove links\n",
    "#df2 = df.drop(['link'], axis=1)\n",
    "\n",
    "# Reorder the columns:\n",
    "df2 = df2[['date', 'title', 'author', 'speech_text']]\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1536ee6",
   "metadata": {},
   "source": [
    "#\n",
    "### Adding the 'is_gov' row\n",
    "The BoE governor for the period in the dataframe (2022-10-20 - present) is Andrew Bailey\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "352b69c3",
   "metadata": {},
   "source": [
    "Let's write a function that checks the last names of the authors. If they match the governor's, is_gov=1. Else, is_gov=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402afdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of last names of BoE Governors from 1998 to 2022\n",
    "governors_last_names = [\"Bailey\"]\n",
    "\n",
    "# Function to check if the author is a governor\n",
    "def is_governor(author):\n",
    "    if pd.isna(author):\n",
    "        return 0\n",
    "    return int(any(last_name in author for last_name in governors_last_names))\n",
    "\n",
    "# Apply the function and insert the column after 'author'\n",
    "df2.insert(loc=df2.columns.get_loc('author') + 1, column='is_gov', value=df2['author'].apply(is_governor))\n",
    "\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530e85a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check\n",
    "print(df2[df2['is_gov'] == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600d4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ef6fa2",
   "metadata": {},
   "source": [
    "### Sorting and saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1bf1385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "df2 = df2.rename(columns={'speech_text': 'text'})\n",
    "\n",
    "# Sort ascending\n",
    "df2 = df2.sort_values(by='date', ascending=True)\n",
    "\n",
    "# save the file\n",
    "df2.to_csv(\"recent_speeches_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9e6f78-f9fb-44cb-81d6-c6a46ff93a4c",
   "metadata": {},
   "source": [
    "#\n",
    "# Manual tweaks\n",
    "After inspecting the saved file, some manual procedures were performed to further complete the data:\n",
    "- 20 names for 'author' where added when scraping was unsuccesfull. The names where found on the 'speech by' part of the titles.\n",
    "- 38 speeches showed 'Speech section not found'. This was probably due to inconsistencies on the HTML structures of every speech details page. The contents where manually copied and pasted to the CSV in Excel\n",
    "- A speech by David Bailey was labeled as true for 'is_gov' column. This mistake was corrected (Only Andrew Bailey's speeches should be true for the period examined)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "653282b3-ed49-429b-8127-da179b34e114",
   "metadata": {},
   "source": [
    "#\n",
    "# Final Dataset\n",
    "After completing the missing data in Excel, we exported the final 'recent_speeches' file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5986def-1304-486f-a705-18c66186ea27",
   "metadata": {},
   "outputs": [],
   "source": [
    "recent_speeches = pd.read_excel('recent speeches_v2.xlsx')\n",
    "recent_speeches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9e001c-f2a6-433a-9934-eebbeb774296",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
